{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e9713b7-90d9-4958-8f09-c4f4a4d472e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import keras\n",
    "from keras import ops # operations for tensor manipulation functions\n",
    "from keras import layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "25e26d06-8a64-43b8-bdbc-589e96e71831",
   "metadata": {},
   "outputs": [],
   "source": [
    "class TransformerBlock(layers.Layer):\n",
    "    def __init__(self, embed_dim, num_heads, ff_dim, rate=0.1):\n",
    "        super().__init__()\n",
    "        self.att = layers.MultiHeadAttention(num_heads=num_heads, key_dim=embed_dim)\n",
    "        self.ffn = keras.Sequential(\n",
    "            [layers.Dense(ff_dim, activation=\"relu\"), layers.Dense(embed_dim),]\n",
    "        )\n",
    "        self.layernorm1 = layers.LayerNormalization(epsilon=1e-6)\n",
    "        self.layernorm2 = layers.LayerNormalization(epsilon=1e-6)\n",
    "        self.dropout1 = layers.Dropout(rate)\n",
    "        self.dropout2 = layers.Dropout(rate)\n",
    "\n",
    "    def call(self, inputs):\n",
    "        attn_output = self.att(inputs, inputs)\n",
    "        attn_output = self.dropout1(attn_output)\n",
    "        out1 = self.layernorm1(inputs + attn_output)\n",
    "        ffn_output = self.ffn(out1)\n",
    "        ffn_output = self.dropout2(ffn_output)\n",
    "        return self.layernorm2(out1 + ffn_output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "fe112d3f-f1db-4f4c-9cb9-cd469b58e3b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "class TokenAndPositionEmbedding(layers.Layer):\n",
    "    def __init__(self, maxlen, vocab_size, embed_dim):\n",
    "        super().__init__()\n",
    "        self.token_emb = layers.Embedding(input_dim=vocab_size, output_dim=embed_dim)\n",
    "        self.pos_emb = layers.Embedding(input_dim=maxlen, output_dim=embed_dim)\n",
    "\n",
    "    def call(self, x):\n",
    "        maxlen = ops.shape(x)[-1]\n",
    "        positions = ops.arange(start=0, stop=maxlen, step=1)\n",
    "        positions = self.pos_emb(positions)\n",
    "        x = self.token_emb(x)\n",
    "        return x + positions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "983f93f8-d576-4ff4-8614-d56d92212d82",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training sequences: 25000\n",
      "Validation sequences: 25000\n"
     ]
    }
   ],
   "source": [
    "vocab_size = 20000 # only top 20K words\n",
    "max_len = 200 # only top 200 words in each movie review\n",
    "\n",
    "(X_train, y_train), (X_val, y_val) = keras.datasets.imdb.load_data(num_words=vocab_size)\n",
    "print(f\"Training sequences: {len(X_train)}\")\n",
    "print(f\"Validation sequences: {len(X_val)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "bf227914-9521-4866-9c40-578a43535c07",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = keras.utils.pad_sequences(X_train, maxlen=max_len)\n",
    "X_val = keras.utils.pad_sequences(X_val, maxlen=max_len)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "adad32af-f7a5-4f06-9be9-de8a769aae04",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[   5,   25,  100, ...,   19,  178,   32],\n",
       "       [   0,    0,    0, ...,   16,  145,   95],\n",
       "       [   0,    0,    0, ...,    7,  129,  113],\n",
       "       ...,\n",
       "       [   0,    0,    0, ...,    4, 3586,    2],\n",
       "       [   0,    0,    0, ...,   12,    9,   23],\n",
       "       [   0,    0,    0, ...,  204,  131,    9]])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "bc1634e4-a1df-4150-8a53-ef59a84a7019",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create input layer\n",
    "inputs = layers.Input(shape=(max_len,))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "9a0e6455-1c1a-4305-9652-31d2e36af96b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\sselc\\anaconda3\\Lib\\site-packages\\keras\\src\\backend\\tensorflow\\core.py:188: The name tf.placeholder is deprecated. Please use tf.compat.v1.placeholder instead.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Create embedding layer\n",
    "embed_dim = 32 # Embedding dimension for each token\n",
    "embedding_layer = TokenAndPositionEmbedding(max_len, vocab_size, embed_dim)\n",
    "x = embedding_layer(inputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "c1eb110f-977a-419f-b5c2-7b6e9a0b3b74",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create transformer layer\n",
    "num_heads = 2 # attention heads\n",
    "ff_dim = 32 # hidden layer size in FFN inside transformer\n",
    "transformer_block = TransformerBlock(embed_dim, num_heads, ff_dim)\n",
    "x = transformer_block(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "3967b0e8-8db7-42f5-b2e8-6b71eb9b032e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Apply global average pooling to output - reduce spatial dimension\n",
    "x = layers.GlobalAveragePooling1D()(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "5426d0cc-1d3d-456f-a0c9-e81035799fcd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Apply dropout regularization - randomly setting fractions of inputs to 0 to avaoid overfitting\n",
    "x = layers.Dropout(0.1)(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "260b0c1b-dcb7-48ec-8d0d-a3c841c064ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add 20 dense layers and ReLU to learn non-linear relationships\n",
    "x = layers.Dense(20, activation='relu')(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "2c029036-4095-47a5-97f2-453caa14d157",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Apply dropout regularization - randomly setting fractions of inputs to 0 to avaoid overfitting\n",
    "x = layers.Dropout(0.1)(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "080db1de-3470-4012-b645-37509ba8120a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create output layer - 2 dense layers and softmax for binary classification\n",
    "# Softmax - converts output values to probabilities\n",
    "outputs = layers.Dense(2, activation='softmax')(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "c96f7bac-ac00-415f-8422-4c335bacb510",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create model\n",
    "model = keras.Model(inputs=inputs, outputs=outputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "6ac7804a-1910-4691-8f46-903a8dc234dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compile the model\n",
    "model.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "82c0f23b-df27-4d60-84af-7dacdbd40294",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/2\n",
      "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m32s\u001b[0m 32ms/step - accuracy: 0.7092 - loss: 0.5250 - val_accuracy: 0.8779 - val_loss: 0.2898\n",
      "Epoch 2/2\n",
      "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m25s\u001b[0m 31ms/step - accuracy: 0.9287 - loss: 0.1964 - val_accuracy: 0.8743 - val_loss: 0.3053\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(X_train, y_train, batch_size=32, epochs=2, validation_data=(X_val, y_val))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "bf586dfc-cf6c-48ed-bd14-1023b7f546d1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 328ms/step\n",
      "Predicted class probabilities: [[0.9364726  0.06352738]]\n",
      "Predicted class: 0\n"
     ]
    }
   ],
   "source": [
    "# Assuming `model` is your trained model\n",
    "import numpy as np\n",
    "# Make predictions on a single input sequence\n",
    "input_sequence = X_val[0]  # Example input sequence from validation data\n",
    "input_sequence = input_sequence.reshape(1, -1)  # Reshape to match model input shape\n",
    "predictions = model.predict(input_sequence)\n",
    "\n",
    "# Print the predicted class probabilities\n",
    "print(\"Predicted class probabilities:\", predictions)\n",
    "\n",
    "# Get the predicted class label (0 or 1)\n",
    "predicted_class = np.argmax(predictions)\n",
    "print(\"Predicted class:\", predicted_class)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a9a0149-f6e0-4aa0-8884-ae53a30b315d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
